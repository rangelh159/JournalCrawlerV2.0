# üìö Cat√°logo de Revistas Acad√©micas SCImago

Este proyecto permite automatizar la recopilaci√≥n, organizaci√≥n y visualizaci√≥n de informaci√≥n sobre revistas acad√©micas indexadas en SCImago. El sistema consta de tres partes: procesamiento de archivos CSV, extracci√≥n de datos desde SCImago mediante web scraping y una interfaz gr√°fica que permite explorar la informaci√≥n por diferentes criterios.

---

## üîß Instrucciones para ejecutar el programa

### 1. Preprocesamiento de datos

El archivo ***csv_to_json.py*** sirve para organizar informaci√≥n de revistas contenida en archivos CSV y guardarla en un solo archivo JSON. Utiliza dos carpetas: una con archivos que indican a qu√© √°reas pertenece cada revista, y otra con archivos que muestran en qu√© cat√°logos est√° incluida. A partir de esta informaci√≥n, el archivo agrupa las revistas y registra sus √°reas y cat√°logos, guardando todo en un formato m√°s f√°cil de manejar y consultar.

**Para generar un archivo JSON:**
1. Abre una terminal y navega hasta la carpeta *funciones* donde se encuentra *csv_to_json.py*
2. Ejecuta el archivo con Python: python *csv_to_json.py*

O bien, pruebe corriendo el archivo *csv_to_json.py* ubicado en la carpeta *funciones*.

Al finalizar, se generar√° un archivo llamado revistas.json en la ruta: ../datos/json/revistas.json

### 2. Web Scraping de SCImago

El archivo ***scrapper.py*** se encarga de buscar informaci√≥n detallada sobre cada revista en el sitio web *scimagojr.com*, usando el archivo *revistas.json* generado en el paso anterior. Para cada revista, extrae datos como el H-index, sitio web, ISSN, widget, √°rea tem√°tica de cada revista, entre otros.

Este proceso automatizado permite actualizar la informaci√≥n sin necesidad de hacerlo manualmente, y guarda los resultados en un nuevo archivo JSON m√°s completo.

**Para ejecutar el scraper:**
1. Abre una terminal y ub√≠cate en la carpeta donde est√° *scrapper.py*
2. Ejecuta: python scrapper.py -a "ruta_al_archivo_revistas.json" -p (primer titulo en n√∫mero) -u (√∫ltimo titulo en n√∫mero) -o "ruta_al_archivo_de_salida.json"
       Significado de los par√°metros:
        -a: Archivo de entrada ‚Üí Ruta al archivo *revistas.json* que contiene la informaci√≥n base sobre las revistas (generado por el csv_to_json.py).
        -p: Primer archivo ‚Üí √çndice (entero) desde donde comenzar el scraping. Por ejemplo, -p 0 inicia desde el principio.
        -u: √öltimo archivo ‚Üí √çndice (entero) desde donde terminar el scraping.
        -o: Archivo de salida ‚Üí Ruta donde se guardar√° el nuevo archivo JSON con la informaci√≥n obtenida desde SCImago, ejemplo para este caso: salida.json.
4. Se generar√° un archivo llamado "salida.json" en la ruta especificada, listo para ser usado por la p√°gina web.

Nota: Es necesario tener buena conexi√≥n a internet.

### 3. Interfaz gr√°fica

La parte visual del sistema est√° desarrollada con Flask y Bootstrap. Esta interfaz permite navegar f√°cilmente por la informaci√≥n de las revistas ya procesadas. Se pueden explorar revistas por:
1. cat√°logo,
2. √°rea tem√°tica,
3. nombre.

**Para ejecutar la app:**
1. Abre una terminal en la carpeta principal del proyecto
2. Ejecuta: python app.py
3. Abre un navegador y ve a [http://localhost:5000].

Dentro de la interfaz navegue por las funcionalidades de la barra de navegaci√≥n.

## üë©‚Äçüíª Colaboradoras

* MEREDES MARIANA PERALTA HURTADO
* HILARY DEL CARMEN RANGEL ZAMBRANO
* SOFIA PAOLA SHOUP MORALES

---

## üí° Nota sobre el uso de inteligencia artificial

Durante el desarrollo del presente proyecto, se utiliz√≥ el apoyo de un asistente virtual basado en inteligencia artificial (ChatGPT de OpenAI) para generar sugerencias de nombres, redactar textos explicativos, aclarar dudas sobre la estructura del programa y  optimizar fragmentos de c√≥digo (tambi√©n Copilot para estos dos √∫ltimos).
